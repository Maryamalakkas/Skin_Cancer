{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNdDQEobqKII",
        "outputId": "aa32d5c3-de41-4bd4-e7e1-0b034129acc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/jh/zgqt24qj3_n6m12h05s8spkr0000gn/T/ipykernel_66665/1249265048.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /Users/hneen/miniconda3/lib/python3.11/site-packages (4.3.0)\n",
            "Requirement already satisfied: numpy in /Users/hneen/miniconda3/lib/python3.11/site-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /Users/hneen/miniconda3/lib/python3.11/site-packages (from lightgbm) (1.12.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "88NenbxiqKIJ"
      },
      "outputs": [],
      "source": [
        "random_state=42\n",
        "best_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "VY2BqdWOqKIJ",
        "outputId": "aedf2944-28cb-4d62-de33-8c0e671e78df"
      },
      "outputs": [],
      "source": [
        "# Read in the data\n",
        "# Read in the data\n",
        "df = pd.read_csv('../Data/Final_skin_cancer.csv')\n",
        "\n",
        "df.drop('drink', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQX8dggmPB8c"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uNLe-VlTqKIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def splitting_data(df, sampling, test_size=0.2, random_state=123):\n",
        "    # First, split the data into features and target variable\n",
        "    X = df.drop(['diagnostic'], axis=1)\n",
        "    y = df['diagnostic']\n",
        "    \n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "    \n",
        "    # Apply sampling methods to the training data based on the specified method\n",
        "    if sampling == 'none':\n",
        "        return X_train, X_test, y_train, y_test\n",
        "    elif sampling == 'SMOTEENN':\n",
        "        from imblearn.combine import SMOTEENN\n",
        "        smote_enn = SMOTEENN(random_state=random_state)\n",
        "        X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
        "        return X_resampled, X_test, y_resampled, y_test\n",
        "    elif sampling == 'SMOTE':\n",
        "        from imblearn.over_sampling import SMOTE\n",
        "        smote = SMOTE(random_state=random_state)\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "        return X_resampled, X_test, y_resampled, y_test\n",
        "    elif sampling == 'under':\n",
        "        from imblearn.under_sampling import RandomUnderSampler\n",
        "        rus = RandomUnderSampler(random_state=random_state)\n",
        "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "        return X_resampled, X_test, y_resampled, y_test\n",
        "    elif sampling == 'over':\n",
        "        from imblearn.over_sampling import RandomOverSampler\n",
        "        rus = RandomOverSampler(random_state=random_state)\n",
        "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "        return X_resampled, X_test, y_resampled, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lVVxj7KAqKIK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def training(X_train, y_train):\n",
        "    # Create a KNN classifier with 5 neighbors\n",
        "    LGBM = SVC()\n",
        "    # Fit the classifier to the data\n",
        "    LGBM.fit(X_train, y_train)\n",
        "    return LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Zc5GvysOfGU"
      },
      "outputs": [],
      "source": [
        "def best_model(modelName, accuracy, precision, recall, f1):\n",
        "    best_models[modelName] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qx40EAZCqKIK"
      },
      "outputs": [],
      "source": [
        "def predict(modleName,LGBM, X_test ,y_test):\n",
        "    # Predict the labels for the training data X\n",
        "    y_pred = LGBM.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cr=classification_report(y_test, y_pred, output_dict=True)\n",
        "    precision = cr['weighted avg']['precision']\n",
        "    recall = cr['weighted avg']['recall']\n",
        "    f1 = cr['weighted avg']['f1-score']\n",
        "    best_model(modleName,accuracy,precision,recall,f1)\n",
        "    cr=classification_report(y_test, y_pred)\n",
        "    print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAOn-8uqKIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RaCvmccpqKIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def optimize_with_grid(X_train, y_train):\n",
        "    # Define a pipeline that first scales the data and then applies the classifier\n",
        "    # Scaling is more critical for SVM than for Decision Trees\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Uncommenting this as it's important for SVM\n",
        "        ('svm', SVC(random_state=random_state))\n",
        "    ])\n",
        "\n",
        "    # Define the parameter grid to search\n",
        "    param_grid = {\n",
        "        'svm__C': [0.1, 1, 10, 100],  # Regularization parameter\n",
        "        'svm__gamma': [1, 0.1, 0.01, 0.001],  # Kernel coefficient for 'rbf', 'poly' and 'sigmoid'\n",
        "        'svm__kernel': ['rbf', 'poly', 'sigmoid']  # Type of kernel\n",
        "    }\n",
        "\n",
        "    # Create the GridSearchCV object\n",
        "    svm_cv = GridSearchCV(pipe, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "    # Perform the grid search on the provided data\n",
        "    svm_cv.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = svm_cv.best_params_\n",
        "    best_score = svm_cv.best_score_\n",
        "    best_estimator = svm_cv.best_estimator_\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Score:\", best_score)\n",
        "\n",
        "    return best_estimator\n",
        "\n",
        "# Example usage (you need to define X_train, y_train, and random_state before calling this function)\n",
        "# best_svm_model = optimize_with_grid_svm(X_train, y_train, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymbIYYOgqKIK"
      },
      "source": [
        "<h1> LGBM on original data with optimization </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jNHPeleDqKIL"
      },
      "outputs": [],
      "source": [
        "# using function with no sampling\n",
        "X_train, X_test, y_train, y_test = splitting_data(df, 'none')\n",
        "# Split the data into train and test sets\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9HGLHNvqKIL",
        "outputId": "c660b805-d8f7-48c0-fa12-e342f729c21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "diagnostic\n",
            "1    1192\n",
            "0     172\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo1V3LfNqKIL",
        "outputId": "c81988db-7320-4803-9ca0-12ca8e6c7bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.54      0.65        39\n",
            "           1       0.94      0.98      0.96       302\n",
            "\n",
            "    accuracy                           0.93       341\n",
            "   macro avg       0.88      0.76      0.80       341\n",
            "weighted avg       0.93      0.93      0.93       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM1 = training(X_train, y_train)\n",
        "y_pred = predict('original',LGBM1, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiCcN4wtqKIL",
        "outputId": "4e26eff9-8da4-4ff5-da45-f6ee6add49bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
            "Best Score: 0.9245017237664296\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.59      0.68        39\n",
            "           1       0.95      0.98      0.96       302\n",
            "\n",
            "    accuracy                           0.94       341\n",
            "   macro avg       0.87      0.78      0.82       341\n",
            "weighted avg       0.93      0.94      0.93       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM1 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('original_grid',best_LGBM1, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP50kI6HqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTE sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5QC5Nt4VqKIM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = splitting_data(df, 'SMOTE')\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEyeNwUYqKIM",
        "outputId": "94a381cc-d663-43ce-d9cf-da3a66c45504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "diagnostic\n",
            "1    1192\n",
            "0    1192\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMPzo7yqKIM",
        "outputId": "1d2f5b71-0bf7-4602-a281-d7746a86a9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.85      0.67        39\n",
            "           1       0.98      0.91      0.95       302\n",
            "\n",
            "    accuracy                           0.91       341\n",
            "   macro avg       0.77      0.88      0.81       341\n",
            "weighted avg       0.93      0.91      0.91       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM2 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTE',LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7dtp3BqKIM",
        "outputId": "62195fb4-fddf-44c0-fecc-fbb9be395327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "Best Parameters: {'svm__C': 100, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
            "Best Score: 0.9324753800891425\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.79      0.72        39\n",
            "           1       0.97      0.95      0.96       302\n",
            "\n",
            "    accuracy                           0.93       341\n",
            "   macro avg       0.82      0.87      0.84       341\n",
            "weighted avg       0.94      0.93      0.93       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM2 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTE_grid',best_LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqQKWnBOqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTEENN sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i2oPMW0QqKIM"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = splitting_data(df, 'SMOTEENN')\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBW__2vqKIM",
        "outputId": "cc80040a-d73b-4335-d3dc-2cc8f82ff736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "1    1018\n",
            "0     933\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAArrZCsqKIM",
        "outputId": "ceea8710-93d1-4430-d8bc-3be4458ec2d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.79      0.62        39\n",
            "           1       0.97      0.90      0.93       302\n",
            "\n",
            "    accuracy                           0.89       341\n",
            "   macro avg       0.74      0.85      0.78       341\n",
            "weighted avg       0.92      0.89      0.90       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM3 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTEENN',LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n30gjeRDUJwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugU45SBeTyNO",
        "outputId": "de07c078-08cd-4073-8547-683066c35f25"
      },
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "# dump(LGBM3,'/content/LGBM_SMOTEENN.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "coDgVriNUIdg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJO13pfyqKIM",
        "outputId": "fd440418-7f80-42a0-e35c-ddd737434e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "Best Parameters: {'svm__C': 100, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
            "Best Score: 0.9784838350055741\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.82      0.69        39\n",
            "           1       0.98      0.93      0.95       302\n",
            "\n",
            "    accuracy                           0.91       341\n",
            "   macro avg       0.78      0.87      0.82       341\n",
            "weighted avg       0.93      0.91      0.92       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM3 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTEENN_grid',best_LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PnNxWS7qKIN"
      },
      "source": [
        "<h1> DT on Random undersampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hyBeGwkxqKIN"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = splitting_data(df, 'under')\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CngNW2VoqKIN",
        "outputId": "4e5988f1-e887-494e-9094-9f36ec80c007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "0    172\n",
            "1    172\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfctngdqKIN",
        "outputId": "5f3cc946-e233-4d0d-8dc9-5981be847412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.95      0.65        39\n",
            "           1       0.99      0.87      0.93       302\n",
            "\n",
            "    accuracy                           0.88       341\n",
            "   macro avg       0.74      0.91      0.79       341\n",
            "weighted avg       0.94      0.88      0.90       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM4 =training(X_train, y_train)\n",
        "y_pred = predict('undersampling',LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gphc1Qn_qKIN",
        "outputId": "0209143e-94d9-4d5a-83c3-3ae43c82854d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "Best Parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
            "Best Score: 0.8837169650468883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.90      0.62        39\n",
            "           1       0.99      0.87      0.92       302\n",
            "\n",
            "    accuracy                           0.87       341\n",
            "   macro avg       0.73      0.88      0.77       341\n",
            "weighted avg       0.93      0.87      0.89       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM4 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('undersampling_grid',best_LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwX52mz6rJQM"
      },
      "source": [
        "<h1> DT on Random Oversampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vRNY2IctrJQY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = splitting_data(df, 'over')\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fQJF0p-rJQY",
        "outputId": "91d1cd54-a355-432b-d511-8707f92a9812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "1    1192\n",
            "0    1192\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y_train.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHyDEyJMrJQZ",
        "outputId": "910b50ab-9f84-4f3b-a9b6-67de99d6a906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.54      0.92      0.68        39\n",
            "           1       0.99      0.90      0.94       302\n",
            "\n",
            "    accuracy                           0.90       341\n",
            "   macro avg       0.76      0.91      0.81       341\n",
            "weighted avg       0.94      0.90      0.91       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM5 =training(X_train, y_train)\n",
        "y_pred = predict('oversampling',LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtbUa8ZIrrWY",
        "outputId": "f506ca33-9fd4-46a6-f8ae-21d1e14b7de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
            "Best Parameters: {'svm__C': 10, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
            "Best Score: 0.9286947483395874\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.85      0.67        39\n",
            "           1       0.98      0.91      0.94       302\n",
            "\n",
            "    accuracy                           0.90       341\n",
            "   macro avg       0.76      0.88      0.81       341\n",
            "weighted avg       0.93      0.90      0.91       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM5 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('oversampling_grid',best_LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_KHeS-NAOfGc",
        "outputId": "b266a67b-2bac-4887-cb70-63238ab818dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original_grid</th>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.930920</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.931265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>original</th>\n",
              "      <td>0.932551</td>\n",
              "      <td>0.927398</td>\n",
              "      <td>0.932551</td>\n",
              "      <td>0.926517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTE_grid</th>\n",
              "      <td>0.929619</td>\n",
              "      <td>0.936967</td>\n",
              "      <td>0.929619</td>\n",
              "      <td>0.932420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTEENN_grid</th>\n",
              "      <td>0.914956</td>\n",
              "      <td>0.931804</td>\n",
              "      <td>0.914956</td>\n",
              "      <td>0.920731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTE</th>\n",
              "      <td>0.906158</td>\n",
              "      <td>0.930757</td>\n",
              "      <td>0.906158</td>\n",
              "      <td>0.914127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oversampling_grid</th>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.929623</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.911747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oversampling</th>\n",
              "      <td>0.900293</td>\n",
              "      <td>0.937386</td>\n",
              "      <td>0.900293</td>\n",
              "      <td>0.911039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTEENN</th>\n",
              "      <td>0.888563</td>\n",
              "      <td>0.918449</td>\n",
              "      <td>0.888563</td>\n",
              "      <td>0.898715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>undersampling</th>\n",
              "      <td>0.882698</td>\n",
              "      <td>0.935394</td>\n",
              "      <td>0.882698</td>\n",
              "      <td>0.897502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>undersampling_grid</th>\n",
              "      <td>0.873900</td>\n",
              "      <td>0.926456</td>\n",
              "      <td>0.873900</td>\n",
              "      <td>0.889551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  precision    recall        f1\n",
              "original_grid       0.935484   0.930920  0.935484  0.931265\n",
              "original            0.932551   0.927398  0.932551  0.926517\n",
              "SMOTE_grid          0.929619   0.936967  0.929619  0.932420\n",
              "SMOTEENN_grid       0.914956   0.931804  0.914956  0.920731\n",
              "SMOTE               0.906158   0.930757  0.906158  0.914127\n",
              "oversampling_grid   0.903226   0.929623  0.903226  0.911747\n",
              "oversampling        0.900293   0.937386  0.900293  0.911039\n",
              "SMOTEENN            0.888563   0.918449  0.888563  0.898715\n",
              "undersampling       0.882698   0.935394  0.882698  0.897502\n",
              "undersampling_grid  0.873900   0.926456  0.873900  0.889551"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_df = pd.DataFrame.from_dict(best_models, orient='index')\n",
        "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "best_model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ECXu3QQryM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
