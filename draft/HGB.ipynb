{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "random_state=42\n",
    "best_models = {}\n",
    "\n",
    "df = pd.read_csv('../Data/Final_skin_cancer.csv')\n",
    "df.drop('drink', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['fitspatrick','region_hash_0','region_hash_1','region_hash_2','region_hash_3','region_hash_4','region_hash_5','region_hash_6','region_hash_7','region_hash_8','region_hash_9','changed','bleed','elevation','biopsed','diameter_2','diameter_1','itch','grew','hurt'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def splitting_data(df, sampling):\n",
    "    X = df.drop(['diagnostic'], axis=1)\n",
    "    y = df['diagnostic']\n",
    "\n",
    "    if sampling == 'none':\n",
    "        return X, y\n",
    "    elif sampling == 'SMOTEENN':\n",
    "        sampler = SMOTEENN(random_state=random_state)\n",
    "    elif sampling == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    elif sampling == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    elif sampling == 'over':\n",
    "        sampler = RandomOverSampler(random_state=random_state)\n",
    "    elif sampling == 'cluster_centroids':\n",
    "        sampler = ClusterCentroids(random_state=random_state)\n",
    "    elif sampling == 'tomek_links':\n",
    "        sampler = TomekLinks()\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(X_train, y_train):\n",
    "\n",
    "    HGB = HistGradientBoostingClassifier()\n",
    "    # Fit the classifier to the data\n",
    "    HGB.fit(X_train, y_train)\n",
    "    return HGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(modelName, accuracy, precision, recall, f1):\n",
    "    best_models[modelName] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(HGB, X_test ,y_test):\n",
    "    # Predict the labels for the training data X\n",
    "    y_pred = HGB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cr=classification_report(y_test, y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def optimize_with_grid(X_train, y_train):\n",
    "\n",
    "    # Initialize the LGBMClassifier\n",
    "    HGB = HistGradientBoostingClassifier()\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'max_iter': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'min_samples_leaf': [20, 40, 60]\n",
    "    }\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    HGB_cv = GridSearchCV(HGB, param_grid, cv=5)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    HGB_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    best_params = HGB_cv.best_params_\n",
    "    best_score = HGB_cv.best_score_\n",
    "    best_estimator = HGB_cv.best_estimator_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function with no sampling\n",
    "X, y= splitting_data(df, 'none')\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "diagnostic\n",
      "1    1494\n",
      "0     211\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78        37\n",
      "           1       0.97      0.98      0.98       304\n",
      "\n",
      "    accuracy                           0.96       341\n",
      "   macro avg       0.91      0.86      0.88       341\n",
      "weighted avg       0.95      0.96      0.95       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB1 = training(X_train, y_train)\n",
    "y_pred = predict(HGB1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 200, 'min_samples_leaf': 20}\n",
      "0.942073367808662\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "predict() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m best_HGB1 \u001b[38;5;241m=\u001b[39m optimize_with_grid(X_train, y_train)\n\u001b[0;32m----> 2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal_grid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mbest_HGB1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "best_HGB1 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('original_grid',best_HGB1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE for over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'SMOTE')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1013\n",
      "0    1013\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       211\n",
      "           1       0.88      0.86      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB2 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTE',HGB2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 60}\n",
      "0.8925925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       211\n",
      "           1       0.89      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB2 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTE_grid',best_HGB2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB using SMOTEENN sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'SMOTEENN')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    156\n",
      "0    137\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77        24\n",
      "           1       0.82      0.91      0.86        35\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.84      0.81      0.82        59\n",
      "weighted avg       0.83      0.83      0.83        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB3 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTEENN',HGB3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/HGB3_SMOTEENN.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from joblib import dump\n",
    "# dump(HGB3,'../Models/HGB3_SMOTEENN.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 3, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "0.8332099907493061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        24\n",
      "           1       0.91      0.91      0.91        35\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.89      0.89      0.89        59\n",
      "weighted avg       0.90      0.90      0.90        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB3 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTEENN_grid',best_HGB3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'under')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       200\n",
      "           1       0.90      0.86      0.88       195\n",
      "\n",
      "    accuracy                           0.89       395\n",
      "   macro avg       0.89      0.89      0.89       395\n",
      "weighted avg       0.89      0.89      0.89       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB4 =training(X_train, y_train)\n",
    "y_pred = predict('under',HGB4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8954992967651195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       200\n",
      "           1       0.88      0.85      0.86       195\n",
      "\n",
      "    accuracy                           0.87       395\n",
      "   macro avg       0.87      0.87      0.87       395\n",
      "weighted avg       0.87      0.87      0.87       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB4 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('under_grid',best_HGB4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'over')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1013\n",
      "0    1013\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       211\n",
      "           1       0.90      0.88      0.89       195\n",
      "\n",
      "    accuracy                           0.89       406\n",
      "   macro avg       0.89      0.89      0.89       406\n",
      "weighted avg       0.89      0.89      0.89       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB5 =training(X_train, y_train)\n",
    "y_pred = predict('over',HGB5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8962962962962964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       211\n",
      "           1       0.90      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB5 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('over_grid',best_HGB5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X,y = splitting_data(data, 'cluster_centroids')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       200\n",
      "           1       0.89      0.86      0.87       195\n",
      "\n",
      "    accuracy                           0.88       395\n",
      "   macro avg       0.88      0.88      0.88       395\n",
      "weighted avg       0.88      0.88      0.88       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB6 =training(X_train, y_train)\n",
    "y_pred = predict('cluster_centroids',HGB6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 40}\n",
      "0.8992947558770343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       200\n",
      "           1       0.89      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.87       395\n",
      "   macro avg       0.87      0.87      0.87       395\n",
      "weighted avg       0.87      0.87      0.87       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB6 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('cluster_centroids_grid',best_HGB6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'tomek_links')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    987\n",
      "0    694\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       139\n",
      "           1       0.91      0.90      0.91       198\n",
      "\n",
      "    accuracy                           0.89       337\n",
      "   macro avg       0.89      0.89      0.89       337\n",
      "weighted avg       0.89      0.89      0.89       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB7 =training(X_train, y_train)\n",
    "y_pred = predict('tomek_links',HGB7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8988237252399711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       139\n",
      "           1       0.92      0.92      0.92       198\n",
      "\n",
      "    accuracy                           0.91       337\n",
      "   macro avg       0.90      0.90      0.90       337\n",
      "weighted avg       0.90      0.91      0.90       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB7 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('tomek_links_grid',best_HGB7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_grid</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.915243</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.915030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912491</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomek_links_grid</th>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.904899</td>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.904939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN_grid</th>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.894226</td>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomek_links</th>\n",
       "      <td>0.890208</td>\n",
       "      <td>0.890339</td>\n",
       "      <td>0.890208</td>\n",
       "      <td>0.890265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886814</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.885984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_grid</th>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.880174</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.879092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.877034</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.876748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE_grid</th>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.877528</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.876652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_centroids</th>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.876367</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.875883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_centroids_grid</th>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873967</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under_grid</th>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.868893</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.868267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN</th>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.832508</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.827385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy  precision    recall        f1\n",
       "original_grid           0.915000   0.915243  0.915000  0.915030\n",
       "original                0.912500   0.912491  0.912500  0.912490\n",
       "tomek_links_grid        0.905045   0.904899  0.905045  0.904939\n",
       "SMOTEENN_grid           0.898305   0.898305  0.898305  0.898305\n",
       "over                    0.894089   0.894226  0.894089  0.894021\n",
       "tomek_links             0.890208   0.890339  0.890208  0.890265\n",
       "under                   0.886076   0.886814  0.886076  0.885984\n",
       "over_grid               0.879310   0.880174  0.879310  0.879092\n",
       "SMOTE                   0.876847   0.877034  0.876847  0.876748\n",
       "SMOTE_grid              0.876847   0.877528  0.876847  0.876652\n",
       "cluster_centroids       0.875949   0.876367  0.875949  0.875883\n",
       "cluster_centroids_grid  0.873418   0.873967  0.873418  0.873333\n",
       "under_grid              0.868354   0.868893  0.868354  0.868267\n",
       "SMOTEENN                0.830508   0.832508  0.830508  0.827385"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_df = pd.DataFrame.from_dict(best_models, orient='index')\n",
    "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "best_model_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
