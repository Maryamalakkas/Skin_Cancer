{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNdDQEobqKII",
        "outputId": "aa32d5c3-de41-4bd4-e7e1-0b034129acc7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/jh/zgqt24qj3_n6m12h05s8spkr0000gn/T/ipykernel_26033/3350206108.py:1: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /Users/hneen/miniconda3/lib/python3.11/site-packages (4.3.0)\n",
            "Requirement already satisfied: numpy in /Users/hneen/miniconda3/lib/python3.11/site-packages (from lightgbm) (1.26.4)\n",
            "Requirement already satisfied: scipy in /Users/hneen/miniconda3/lib/python3.11/site-packages (from lightgbm) (1.12.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "88NenbxiqKIJ"
      },
      "outputs": [],
      "source": [
        "random_state=123\n",
        "best_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "VY2BqdWOqKIJ",
        "outputId": "aedf2944-28cb-4d62-de33-8c0e671e78df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smoke</th>\n",
              "      <th>drink</th>\n",
              "      <th>age</th>\n",
              "      <th>pesticide</th>\n",
              "      <th>gender</th>\n",
              "      <th>skin_cancer_history</th>\n",
              "      <th>cancer_history</th>\n",
              "      <th>has_piped_water</th>\n",
              "      <th>has_sewage_system</th>\n",
              "      <th>fitspatrick</th>\n",
              "      <th>...</th>\n",
              "      <th>region_hash_0</th>\n",
              "      <th>region_hash_1</th>\n",
              "      <th>region_hash_2</th>\n",
              "      <th>region_hash_3</th>\n",
              "      <th>region_hash_4</th>\n",
              "      <th>region_hash_5</th>\n",
              "      <th>region_hash_6</th>\n",
              "      <th>region_hash_7</th>\n",
              "      <th>region_hash_8</th>\n",
              "      <th>region_hash_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>55</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>79</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>52</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>74</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>27</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1702</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1703</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1704</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1705 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      smoke  drink  age  pesticide  gender  skin_cancer_history  \\\n",
              "0     False  False   55      False       0                 True   \n",
              "1     False   True   79      False       1                 True   \n",
              "2     False   True   52      False       0                False   \n",
              "3     False  False   74       True       0                False   \n",
              "4     False   True   58       True       0                 True   \n",
              "...     ...    ...  ...        ...     ...                  ...   \n",
              "1700  False  False   23       True       0                False   \n",
              "1701  False  False   27      False       0                False   \n",
              "1702   True   True   23      False       1                False   \n",
              "1703  False  False   23       True       0                False   \n",
              "1704  False  False   21      False       0                False   \n",
              "\n",
              "      cancer_history  has_piped_water  has_sewage_system  fitspatrick  ...  \\\n",
              "0               True             True               True          3.0  ...   \n",
              "1              False            False              False          1.0  ...   \n",
              "2               True             True               True          3.0  ...   \n",
              "3              False            False              False          1.0  ...   \n",
              "4               True             True               True          1.0  ...   \n",
              "...              ...              ...                ...          ...  ...   \n",
              "1700            True             True               True          0.0  ...   \n",
              "1701           False             True               True          0.0  ...   \n",
              "1702           False             True               True          0.0  ...   \n",
              "1703           False             True              False          0.0  ...   \n",
              "1704           False             True               True          0.0  ...   \n",
              "\n",
              "      region_hash_0  region_hash_1  region_hash_2  region_hash_3  \\\n",
              "0              -1.0           -1.0            0.0            0.0   \n",
              "1               1.0            0.0            2.0            0.0   \n",
              "2               0.0           -1.0            1.0            0.0   \n",
              "3               0.0           -1.0            1.0            0.0   \n",
              "4               1.0            0.0            2.0            0.0   \n",
              "...             ...            ...            ...            ...   \n",
              "1700           -2.0            0.0            1.0            0.0   \n",
              "1701           -2.0            0.0            1.0            0.0   \n",
              "1702           -2.0            0.0            1.0            0.0   \n",
              "1703           -2.0            0.0            1.0            0.0   \n",
              "1704           -2.0            0.0            1.0            0.0   \n",
              "\n",
              "      region_hash_4  region_hash_5  region_hash_6  region_hash_7  \\\n",
              "0               0.0            0.0            0.0            0.0   \n",
              "1               0.0            0.0            0.0            1.0   \n",
              "2               0.0            0.0            0.0            1.0   \n",
              "3               0.0            0.0            0.0            1.0   \n",
              "4               0.0            0.0            0.0            1.0   \n",
              "...             ...            ...            ...            ...   \n",
              "1700           -1.0            0.0            0.0           -3.0   \n",
              "1701           -1.0            0.0            0.0           -3.0   \n",
              "1702           -1.0            0.0            0.0           -3.0   \n",
              "1703           -1.0            0.0            0.0           -3.0   \n",
              "1704           -1.0            0.0            0.0           -3.0   \n",
              "\n",
              "      region_hash_8  region_hash_9  \n",
              "0               0.0            0.0  \n",
              "1              -1.0            2.0  \n",
              "2              -1.0            0.0  \n",
              "3              -1.0            0.0  \n",
              "4              -1.0            2.0  \n",
              "...             ...            ...  \n",
              "1700            0.0            0.0  \n",
              "1701            0.0            0.0  \n",
              "1702            0.0            0.0  \n",
              "1703            0.0            0.0  \n",
              "1704            0.0            0.0  \n",
              "\n",
              "[1705 rows x 50 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read in the data\n",
        "df = pd.read_csv('../Data/hashed_combined.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQX8dggmPB8c"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uNLe-VlTqKIK"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "def splitting_data(df, sampling):\n",
        "    X = df.drop(['diagnostic'], axis=1)\n",
        "    y = df['diagnostic']\n",
        "\n",
        "    if sampling == 'none':\n",
        "        return X, y\n",
        "    elif sampling == 'SMOTEENN':\n",
        "        sampler = SMOTEENN(random_state=random_state)\n",
        "    elif sampling == 'SMOTE':\n",
        "        sampler = SMOTE(random_state=random_state)\n",
        "    elif sampling == 'under':\n",
        "        sampler = RandomUnderSampler(random_state=random_state)\n",
        "    elif sampling == 'over':\n",
        "        sampler = RandomOverSampler(random_state=random_state)\n",
        "    elif sampling == 'cluster_centroids':\n",
        "        sampler = ClusterCentroids(random_state=random_state)\n",
        "    elif sampling == 'tomek_links':\n",
        "        sampler = TomekLinks()\n",
        "\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    return X_resampled, y_resampled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lVVxj7KAqKIK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def training(X_train, y_train):\n",
        "    # Create a KNN classifier with 5 neighbors\n",
        "    LGBM = ExtraTreesClassifier()\n",
        "    # Fit the classifier to the data\n",
        "    LGBM.fit(X_train, y_train)\n",
        "    return LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3Zc5GvysOfGU"
      },
      "outputs": [],
      "source": [
        "def best_model(modelName, accuracy, precision, recall, f1):\n",
        "    best_models[modelName] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Qx40EAZCqKIK"
      },
      "outputs": [],
      "source": [
        "def predict(modleName,LGBM, X_test ,y_test):\n",
        "    # Predict the labels for the training data X\n",
        "    y_pred = LGBM.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cr=classification_report(y_test, y_pred, output_dict=True)\n",
        "    precision = cr['weighted avg']['precision']\n",
        "    recall = cr['weighted avg']['recall']\n",
        "    f1 = cr['weighted avg']['f1-score']\n",
        "    best_model(modleName,accuracy,precision,recall,f1)\n",
        "    cr=classification_report(y_test, y_pred)\n",
        "    print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAOn-8uqKIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RaCvmccpqKIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def optimize_with_grid(X_train, y_train):\n",
        "    # Define a pipeline\n",
        "    # Note: Scaling might not be necessary for tree-based models, but included for consistency\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Optional for ExtraTrees\n",
        "        ('extra_trees', ExtraTreesClassifier(random_state=random_state))\n",
        "    ])\n",
        "\n",
        "    # Define the parameter grid to search\n",
        "    param_grid = {\n",
        "        'extra_trees__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "        'extra_trees__max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "        'extra_trees__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "        'extra_trees__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "        'extra_trees__max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
        "    }\n",
        "\n",
        "    # Create the GridSearchCV object\n",
        "    extra_trees_cv = GridSearchCV(pipe, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "    # Perform the grid search on the provided data\n",
        "    extra_trees_cv.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = extra_trees_cv.best_params_\n",
        "    best_score = extra_trees_cv.best_score_\n",
        "    best_estimator = extra_trees_cv.best_estimator_\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Score:\", best_score)\n",
        "\n",
        "    return best_estimator\n",
        "\n",
        "# Example usage\n",
        "# Ensure you have defined X_train, y_train, and optionally random_state before calling this function\n",
        "# best_extra_trees_model = optimize_with_grid_extra_trees(X_train, y_train, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymbIYYOgqKIK"
      },
      "source": [
        "<h1> LGBM on original data with optimization </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jNHPeleDqKIL"
      },
      "outputs": [],
      "source": [
        "# using function with no sampling\n",
        "X, y= splitting_data(df, 'none')\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9HGLHNvqKIL",
        "outputId": "c660b805-d8f7-48c0-fa12-e342f729c21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "diagnostic\n",
            "1    1494\n",
            "0     211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo1V3LfNqKIL",
        "outputId": "c81988db-7320-4803-9ca0-12ca8e6c7bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        39\n",
            "           1       1.00      1.00      1.00       302\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      1.00      1.00       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM1 = training(X_train, y_train)\n",
        "y_pred = predict('original',LGBM1, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiCcN4wtqKIL",
        "outputId": "4e26eff9-8da4-4ff5-da45-f6ee6add49bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        39\n",
            "           1       1.00      1.00      1.00       302\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      1.00      1.00       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "421 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "119 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [      nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan 1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        0.9985348 0.9985348 0.9977995 0.9985348\n",
            " 0.9985348 0.9977995 0.9985348 0.9977995 0.9977995 1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9985348 0.9977995 0.9977995 0.9985348 0.9977995\n",
            " 0.9977995 0.9977995 0.9977995 0.9977995       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan 1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 0.9985348 0.9985348 0.9977995 0.9985348 0.9985348 0.9977995 0.9985348\n",
            " 0.9977995 0.9977995 1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9985348\n",
            " 0.9977995 0.9977995 0.9985348 0.9977995 0.9977995 0.9977995 0.9977995\n",
            " 0.9977995       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        0.9985348 0.9985348 0.9977995\n",
            " 0.9985348 0.9985348 0.9977995 0.9985348 0.9977995 0.9977995 1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9985348 0.9977995 0.9977995 0.9985348\n",
            " 0.9977995 0.9977995 0.9977995 0.9977995 0.9977995       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan 1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        0.9985348 0.9985348 0.9977995 0.9985348 0.9985348 0.9977995\n",
            " 0.9985348 0.9977995 0.9977995 1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9985348 0.9977995 0.9977995 0.9985348 0.9977995 0.9977995 0.9977995\n",
            " 0.9977995 0.9977995]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM1 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('original_grid',best_LGBM1, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP50kI6HqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTE sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "5QC5Nt4VqKIM"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'SMOTE')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEyeNwUYqKIM",
        "outputId": "94a381cc-d663-43ce-d9cf-da3a66c45504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "diagnostic\n",
            "1    1494\n",
            "0    1494\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMPzo7yqKIM",
        "outputId": "1d2f5b71-0bf7-4602-a281-d7746a86a9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM2 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTE',LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7dtp3BqKIM",
        "outputId": "62195fb4-fddf-44c0-fecc-fbb9be395327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "178 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "362 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM2 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTE_grid',best_LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqQKWnBOqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTEENN sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "i2oPMW0QqKIM"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'SMOTEENN')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBW__2vqKIM",
        "outputId": "cc80040a-d73b-4335-d3dc-2cc8f82ff736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "0    1494\n",
            "1    1494\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAArrZCsqKIM",
        "outputId": "ceea8710-93d1-4430-d8bc-3be4458ec2d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       306\n",
            "           1       1.00      1.00      1.00       292\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM3 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTEENN',LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n30gjeRDUJwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugU45SBeTyNO",
        "outputId": "de07c078-08cd-4073-8547-683066c35f25"
      },
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "# dump(LGBM3,'/content/LGBM_SMOTEENN.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "coDgVriNUIdg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJO13pfyqKIM",
        "outputId": "fd440418-7f80-42a0-e35c-ddd737434e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       306\n",
            "           1       1.00      1.00      1.00       292\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "331 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "209 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM3 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTEENN_grid',best_LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PnNxWS7qKIN"
      },
      "source": [
        "<h1> DT on Random undersampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hyBeGwkxqKIN"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'under')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CngNW2VoqKIN",
        "outputId": "4e5988f1-e887-494e-9094-9f36ec80c007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "0    211\n",
            "1    211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfctngdqKIN",
        "outputId": "5f3cc946-e233-4d0d-8dc9-5981be847412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM4 =training(X_train, y_train)\n",
        "y_pred = predict('undersampling',LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gphc1Qn_qKIN",
        "outputId": "0209143e-94d9-4d5a-83c3-3ae43c82854d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "409 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "131 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.99701493 1.         1.         0.99701493\n",
            " 1.         1.         0.99701493        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         0.99701493\n",
            " 1.         1.         0.99701493 1.         1.         0.99701493\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         0.99701493 1.         1.         0.99701493\n",
            " 1.         1.         0.99701493        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         0.99701493\n",
            " 1.         1.         0.99701493 1.         1.         0.99701493]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM4 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('undersampling_grid',best_LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwX52mz6rJQM"
      },
      "source": [
        "<h1> DT on Random Oversampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vRNY2IctrJQY"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'over')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fQJF0p-rJQY",
        "outputId": "91d1cd54-a355-432b-d511-8707f92a9812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "1    1494\n",
            "0    1494\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHyDEyJMrJQZ",
        "outputId": "910b50ab-9f84-4f3b-a9b6-67de99d6a906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM5 =training(X_train, y_train)\n",
        "y_pred = predict('oversampling',LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtbUa8ZIrrWY",
        "outputId": "f506ca33-9fd4-46a6-f8ae-21d1e14b7de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "460 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM5 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('oversampling_grid',best_LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGpTKsmiqKIN"
      },
      "source": [
        "<h1> DT on Cluster Centroids </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkaTFoZVqKIN",
        "outputId": "5dd6d896-8f22-4902-e9ae-fce76914004f"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'cluster_centroids')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS1rSgaxqKIN",
        "outputId": "5962a95b-06f3-41ce-94da-5e35c6e14371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "0    211\n",
            "1    211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqdTB76UqKIN",
        "outputId": "02ab0f35-37e7-44f2-e8e8-1d1add42d954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM6 =training(X_train, y_train)\n",
        "y_pred = predict('cluster_centroids',LGBM6, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EeeuE9NqKIN",
        "outputId": "22fe4910-323a-4447-9c15-6f4c480698dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "310 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "230 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1. nan nan nan nan nan nan nan nan nan\n",
            " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM6 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('cluster_centroids_grid',best_LGBM6, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiouy-TeqKIN"
      },
      "source": [
        "<h1> DT on Tomek Links </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vv9E9_GxqKIN"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'tomek_links')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5JKBcpqKIO",
        "outputId": "45d71ad9-688e-46e1-a3af-2d41bd99ea52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "diagnostic\n",
            "1    1494\n",
            "0     211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhD1_sXpqKIO",
        "outputId": "72705b23-115d-47fd-ed4f-440fd93a52a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        39\n",
            "           1       1.00      1.00      1.00       302\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      1.00      1.00       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM7 =training(X_train, y_train)\n",
        "y_pred = predict('tomek_links',LGBM7, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40edJ6c9qKIO",
        "outputId": "83bc31d7-887c-422e-d40a-9f0763642a14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'sqrt', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        39\n",
            "           1       1.00      1.00      1.00       302\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      1.00      1.00       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:542: FitFailedWarning: \n",
            "540 fits failed out of a total of 1620.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "345 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "195 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 890, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1351, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/pipeline.py\", line 475, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 1344, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of ExtraTreesClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/Users/hneen/miniconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [      nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan 1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        0.9985348 0.9985348 0.9977995 0.9985348\n",
            " 0.9985348 0.9977995 0.9985348 0.9977995 0.9977995 1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9985348 0.9977995 0.9977995 0.9985348 0.9977995\n",
            " 0.9977995 0.9977995 0.9977995 0.9977995       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan 1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 0.9985348 0.9985348 0.9977995 0.9985348 0.9985348 0.9977995 0.9985348\n",
            " 0.9977995 0.9977995 1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9985348\n",
            " 0.9977995 0.9977995 0.9985348 0.9977995 0.9977995 0.9977995 0.9977995\n",
            " 0.9977995       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        0.9985348 0.9985348 0.9977995\n",
            " 0.9985348 0.9985348 0.9977995 0.9985348 0.9977995 0.9977995 1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9985348 0.9977995 0.9977995 0.9985348\n",
            " 0.9977995 0.9977995 0.9977995 0.9977995 0.9977995       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan       nan       nan       nan\n",
            "       nan       nan       nan       nan 1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        1.        1.\n",
            " 1.        0.9985348 0.9985348 0.9977995 0.9985348 0.9985348 0.9977995\n",
            " 0.9985348 0.9977995 0.9977995 1.        1.        1.        1.\n",
            " 1.        1.        1.        1.        1.        0.9992674 0.9992674\n",
            " 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674 0.9992674\n",
            " 0.9985348 0.9977995 0.9977995 0.9985348 0.9977995 0.9977995 0.9977995\n",
            " 0.9977995 0.9977995]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "best_LGBM7 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('tomek_links_grid',best_LGBM7, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_KHeS-NAOfGc",
        "outputId": "b266a67b-2bac-4887-cb70-63238ab818dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>original_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTE</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTE_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTEENN</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SMOTEENN_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>undersampling</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>undersampling_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oversampling</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oversampling_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_centroids</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cluster_centroids_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tomek_links</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tomek_links_grid</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        accuracy  precision  recall   f1\n",
              "original                     1.0        1.0     1.0  1.0\n",
              "original_grid                1.0        1.0     1.0  1.0\n",
              "SMOTE                        1.0        1.0     1.0  1.0\n",
              "SMOTE_grid                   1.0        1.0     1.0  1.0\n",
              "SMOTEENN                     1.0        1.0     1.0  1.0\n",
              "SMOTEENN_grid                1.0        1.0     1.0  1.0\n",
              "undersampling                1.0        1.0     1.0  1.0\n",
              "undersampling_grid           1.0        1.0     1.0  1.0\n",
              "oversampling                 1.0        1.0     1.0  1.0\n",
              "oversampling_grid            1.0        1.0     1.0  1.0\n",
              "cluster_centroids            1.0        1.0     1.0  1.0\n",
              "cluster_centroids_grid       1.0        1.0     1.0  1.0\n",
              "tomek_links                  1.0        1.0     1.0  1.0\n",
              "tomek_links_grid             1.0        1.0     1.0  1.0"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model_df = pd.DataFrame.from_dict(best_models, orient='index')\n",
        "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "best_model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ECXu3QQryM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
