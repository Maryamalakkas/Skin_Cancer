{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoke</th>\n",
       "      <th>drink</th>\n",
       "      <th>age</th>\n",
       "      <th>pesticide</th>\n",
       "      <th>gender</th>\n",
       "      <th>skin_cancer_history</th>\n",
       "      <th>cancer_history</th>\n",
       "      <th>has_piped_water</th>\n",
       "      <th>has_sewage_system</th>\n",
       "      <th>fitspatrick</th>\n",
       "      <th>...</th>\n",
       "      <th>region_hash_0</th>\n",
       "      <th>region_hash_1</th>\n",
       "      <th>region_hash_2</th>\n",
       "      <th>region_hash_3</th>\n",
       "      <th>region_hash_4</th>\n",
       "      <th>region_hash_5</th>\n",
       "      <th>region_hash_6</th>\n",
       "      <th>region_hash_7</th>\n",
       "      <th>region_hash_8</th>\n",
       "      <th>region_hash_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1705 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      smoke  drink  age  pesticide  gender  skin_cancer_history  \\\n",
       "0     False  False   55      False       0                 True   \n",
       "1     False   True   79      False       1                 True   \n",
       "2     False   True   52      False       0                False   \n",
       "3     False  False   74       True       0                False   \n",
       "4     False   True   58       True       0                 True   \n",
       "...     ...    ...  ...        ...     ...                  ...   \n",
       "1700  False  False   23       True       0                False   \n",
       "1701  False  False   27      False       0                False   \n",
       "1702   True   True   23      False       1                False   \n",
       "1703  False  False   23       True       0                False   \n",
       "1704  False  False   21      False       0                False   \n",
       "\n",
       "      cancer_history  has_piped_water  has_sewage_system  fitspatrick  ...  \\\n",
       "0               True             True               True          3.0  ...   \n",
       "1              False            False              False          1.0  ...   \n",
       "2               True             True               True          3.0  ...   \n",
       "3              False            False              False          1.0  ...   \n",
       "4               True             True               True          1.0  ...   \n",
       "...              ...              ...                ...          ...  ...   \n",
       "1700            True             True               True          0.0  ...   \n",
       "1701           False             True               True          0.0  ...   \n",
       "1702           False             True               True          0.0  ...   \n",
       "1703           False             True              False          0.0  ...   \n",
       "1704           False             True               True          0.0  ...   \n",
       "\n",
       "      region_hash_0  region_hash_1  region_hash_2  region_hash_3  \\\n",
       "0              -1.0           -1.0            0.0            0.0   \n",
       "1               1.0            0.0            2.0            0.0   \n",
       "2               0.0           -1.0            1.0            0.0   \n",
       "3               0.0           -1.0            1.0            0.0   \n",
       "4               1.0            0.0            2.0            0.0   \n",
       "...             ...            ...            ...            ...   \n",
       "1700           -2.0            0.0            1.0            0.0   \n",
       "1701           -2.0            0.0            1.0            0.0   \n",
       "1702           -2.0            0.0            1.0            0.0   \n",
       "1703           -2.0            0.0            1.0            0.0   \n",
       "1704           -2.0            0.0            1.0            0.0   \n",
       "\n",
       "      region_hash_4  region_hash_5  region_hash_6  region_hash_7  \\\n",
       "0               0.0            0.0            0.0            0.0   \n",
       "1               0.0            0.0            0.0            1.0   \n",
       "2               0.0            0.0            0.0            1.0   \n",
       "3               0.0            0.0            0.0            1.0   \n",
       "4               0.0            0.0            0.0            1.0   \n",
       "...             ...            ...            ...            ...   \n",
       "1700           -1.0            0.0            0.0           -3.0   \n",
       "1701           -1.0            0.0            0.0           -3.0   \n",
       "1702           -1.0            0.0            0.0           -3.0   \n",
       "1703           -1.0            0.0            0.0           -3.0   \n",
       "1704           -1.0            0.0            0.0           -3.0   \n",
       "\n",
       "      region_hash_8  region_hash_9  \n",
       "0               0.0            0.0  \n",
       "1              -1.0            2.0  \n",
       "2              -1.0            0.0  \n",
       "3              -1.0            0.0  \n",
       "4              -1.0            2.0  \n",
       "...             ...            ...  \n",
       "1700            0.0            0.0  \n",
       "1701            0.0            0.0  \n",
       "1702            0.0            0.0  \n",
       "1703            0.0            0.0  \n",
       "1704            0.0            0.0  \n",
       "\n",
       "[1705 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "random_state=42\n",
    "best_models = {}\n",
    "\n",
    "\n",
    "data = pd.read_csv('../Data/hashed_combined.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def splitting_data(df, sampling):\n",
    "    X = df.drop(['diagnostic'], axis=1)\n",
    "    y = df['diagnostic']\n",
    "\n",
    "    if sampling == 'none':\n",
    "        return X, y\n",
    "    elif sampling == 'SMOTEENN':\n",
    "        sampler = SMOTEENN(random_state=random_state)\n",
    "    elif sampling == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    elif sampling == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    elif sampling == 'over':\n",
    "        sampler = RandomOverSampler(random_state=random_state)\n",
    "    elif sampling == 'cluster_centroids':\n",
    "        sampler = ClusterCentroids(random_state=random_state)\n",
    "    elif sampling == 'tomek_links':\n",
    "        sampler = TomekLinks()\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(X_train, y_train):\n",
    "\n",
    "    HGB = HistGradientBoostingClassifier()\n",
    "    # Fit the classifier to the data\n",
    "    HGB.fit(X_train, y_train)\n",
    "    return HGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(modelName, accuracy, precision, recall, f1):\n",
    "    best_models[modelName] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(HGB, X_test ,y_test):\n",
    "    # Predict the labels for the training data X\n",
    "    y_pred = HGB.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cr=classification_report(y_test, y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def optimize_with_grid(X_train, y_train):\n",
    "\n",
    "    # Initialize the LGBMClassifier\n",
    "    HGB = HistGradientBoostingClassifier()\n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'max_iter': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'min_samples_leaf': [20, 40, 60]\n",
    "    }\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    HGB_cv = GridSearchCV(HGB, param_grid, cv=5)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    HGB_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    best_params = HGB_cv.best_params_\n",
    "    best_score = HGB_cv.best_score_\n",
    "    best_estimator = HGB_cv.best_estimator_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "\n",
    "    return best_estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function with no sampling\n",
    "X, y= splitting_data(data, 'none')\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1494\n",
      "0     211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m HGB1 \u001b[38;5;241m=\u001b[39m training(X_train, y_train)\n\u001b[0;32m----> 2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moriginal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mHGB1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: predict() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "HGB1 = training(X_train, y_train)\n",
    "y_pred = predict('original',HGB1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_HGB1 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('original_grid',best_HGB1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE for over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'SMOTE')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1013\n",
      "0    1013\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88       211\n",
      "           1       0.88      0.86      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB2 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTE',HGB2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 60}\n",
      "0.8925925925925926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       211\n",
      "           1       0.89      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB2 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTE_grid',best_HGB2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB using SMOTEENN sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'SMOTEENN')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    156\n",
      "0    137\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.71      0.77        24\n",
      "           1       0.82      0.91      0.86        35\n",
      "\n",
      "    accuracy                           0.83        59\n",
      "   macro avg       0.84      0.81      0.82        59\n",
      "weighted avg       0.83      0.83      0.83        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB3 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTEENN',HGB3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../Models/HGB3_SMOTEENN.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from joblib import dump\n",
    "# dump(HGB3,'../Models/HGB3_SMOTEENN.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 3, 'max_iter': 300, 'min_samples_leaf': 20}\n",
      "0.8332099907493061\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        24\n",
      "           1       0.91      0.91      0.91        35\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.89      0.89      0.89        59\n",
      "weighted avg       0.90      0.90      0.90        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB3 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTEENN_grid',best_HGB3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'under')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       200\n",
      "           1       0.90      0.86      0.88       195\n",
      "\n",
      "    accuracy                           0.89       395\n",
      "   macro avg       0.89      0.89      0.89       395\n",
      "weighted avg       0.89      0.89      0.89       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB4 =training(X_train, y_train)\n",
    "y_pred = predict('under',HGB4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 7, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8954992967651195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87       200\n",
      "           1       0.88      0.85      0.86       195\n",
      "\n",
      "    accuracy                           0.87       395\n",
      "   macro avg       0.87      0.87      0.87       395\n",
      "weighted avg       0.87      0.87      0.87       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB4 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('under_grid',best_HGB4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'over')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1013\n",
      "0    1013\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       211\n",
      "           1       0.90      0.88      0.89       195\n",
      "\n",
      "    accuracy                           0.89       406\n",
      "   macro avg       0.89      0.89      0.89       406\n",
      "weighted avg       0.89      0.89      0.89       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB5 =training(X_train, y_train)\n",
    "y_pred = predict('over',HGB5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8962962962962964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       211\n",
      "           1       0.90      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.88       406\n",
      "   macro avg       0.88      0.88      0.88       406\n",
      "weighted avg       0.88      0.88      0.88       406\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB5 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('over_grid',best_HGB5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X,y = splitting_data(data, 'cluster_centroids')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "0    987\n",
      "1    987\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       200\n",
      "           1       0.89      0.86      0.87       195\n",
      "\n",
      "    accuracy                           0.88       395\n",
      "   macro avg       0.88      0.88      0.88       395\n",
      "weighted avg       0.88      0.88      0.88       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB6 =training(X_train, y_train)\n",
    "y_pred = predict('cluster_centroids',HGB6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 40}\n",
      "0.8992947558770343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88       200\n",
      "           1       0.89      0.85      0.87       195\n",
      "\n",
      "    accuracy                           0.87       395\n",
      "   macro avg       0.87      0.87      0.87       395\n",
      "weighted avg       0.87      0.87      0.87       395\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB6 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('cluster_centroids_grid',best_HGB6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HGB on Tomek Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(data, 'tomek_links')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    987\n",
      "0    694\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87       139\n",
      "           1       0.91      0.90      0.91       198\n",
      "\n",
      "    accuracy                           0.89       337\n",
      "   macro avg       0.89      0.89      0.89       337\n",
      "weighted avg       0.89      0.89      0.89       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HGB7 =training(X_train, y_train)\n",
    "y_pred = predict('tomek_links',HGB7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_iter': 100, 'min_samples_leaf': 20}\n",
      "0.8988237252399711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       139\n",
      "           1       0.92      0.92      0.92       198\n",
      "\n",
      "    accuracy                           0.91       337\n",
      "   macro avg       0.90      0.90      0.90       337\n",
      "weighted avg       0.90      0.91      0.90       337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_HGB7 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('tomek_links_grid',best_HGB7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>original_grid</th>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.915243</td>\n",
       "      <td>0.915000</td>\n",
       "      <td>0.915030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912491</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>0.912490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomek_links_grid</th>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.904899</td>\n",
       "      <td>0.905045</td>\n",
       "      <td>0.904939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN_grid</th>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.898305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.894226</td>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.894021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tomek_links</th>\n",
       "      <td>0.890208</td>\n",
       "      <td>0.890339</td>\n",
       "      <td>0.890208</td>\n",
       "      <td>0.890265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under</th>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.886814</td>\n",
       "      <td>0.886076</td>\n",
       "      <td>0.885984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_grid</th>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.880174</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.879092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE</th>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.877034</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.876748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTE_grid</th>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.877528</td>\n",
       "      <td>0.876847</td>\n",
       "      <td>0.876652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_centroids</th>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.876367</td>\n",
       "      <td>0.875949</td>\n",
       "      <td>0.875883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cluster_centroids_grid</th>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873967</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>under_grid</th>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.868893</td>\n",
       "      <td>0.868354</td>\n",
       "      <td>0.868267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMOTEENN</th>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.832508</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.827385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy  precision    recall        f1\n",
       "original_grid           0.915000   0.915243  0.915000  0.915030\n",
       "original                0.912500   0.912491  0.912500  0.912490\n",
       "tomek_links_grid        0.905045   0.904899  0.905045  0.904939\n",
       "SMOTEENN_grid           0.898305   0.898305  0.898305  0.898305\n",
       "over                    0.894089   0.894226  0.894089  0.894021\n",
       "tomek_links             0.890208   0.890339  0.890208  0.890265\n",
       "under                   0.886076   0.886814  0.886076  0.885984\n",
       "over_grid               0.879310   0.880174  0.879310  0.879092\n",
       "SMOTE                   0.876847   0.877034  0.876847  0.876748\n",
       "SMOTE_grid              0.876847   0.877528  0.876847  0.876652\n",
       "cluster_centroids       0.875949   0.876367  0.875949  0.875883\n",
       "cluster_centroids_grid  0.873418   0.873967  0.873418  0.873333\n",
       "under_grid              0.868354   0.868893  0.868354  0.868267\n",
       "SMOTEENN                0.830508   0.832508  0.830508  0.827385"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_df = pd.DataFrame.from_dict(best_models, orient='index')\n",
    "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "best_model_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
