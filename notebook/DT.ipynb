{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "best_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoke</th>\n",
       "      <th>drink</th>\n",
       "      <th>age</th>\n",
       "      <th>pesticide</th>\n",
       "      <th>gender</th>\n",
       "      <th>skin_cancer_history</th>\n",
       "      <th>cancer_history</th>\n",
       "      <th>has_piped_water</th>\n",
       "      <th>has_sewage_system</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>...</th>\n",
       "      <th>background_mother_hash_0</th>\n",
       "      <th>background_mother_hash_1</th>\n",
       "      <th>background_mother_hash_2</th>\n",
       "      <th>background_mother_hash_3</th>\n",
       "      <th>background_mother_hash_4</th>\n",
       "      <th>background_mother_hash_5</th>\n",
       "      <th>background_mother_hash_6</th>\n",
       "      <th>background_mother_hash_7</th>\n",
       "      <th>background_mother_hash_8</th>\n",
       "      <th>background_mother_hash_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1705 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      smoke  drink  age  pesticide  gender  skin_cancer_history  \\\n",
       "0     False  False   55      False       0                 True   \n",
       "1     False   True   79      False       1                 True   \n",
       "2     False   True   52      False       0                False   \n",
       "3     False  False   74       True       0                False   \n",
       "4     False   True   58       True       0                 True   \n",
       "...     ...    ...  ...        ...     ...                  ...   \n",
       "1700  False  False   23       True       0                False   \n",
       "1701  False  False   27      False       0                False   \n",
       "1702   True   True   23      False       1                False   \n",
       "1703  False  False   23       True       0                False   \n",
       "1704  False  False   21      False       0                False   \n",
       "\n",
       "      cancer_history  has_piped_water  has_sewage_system  diagnostic  ...  \\\n",
       "0               True             True               True           1  ...   \n",
       "1              False            False              False           1  ...   \n",
       "2               True             True               True           1  ...   \n",
       "3              False            False              False           1  ...   \n",
       "4               True             True               True           1  ...   \n",
       "...              ...              ...                ...         ...  ...   \n",
       "1700            True             True               True           0  ...   \n",
       "1701           False             True               True           0  ...   \n",
       "1702           False             True               True           0  ...   \n",
       "1703           False             True              False           0  ...   \n",
       "1704           False             True               True           0  ...   \n",
       "\n",
       "      background_mother_hash_0  background_mother_hash_1  \\\n",
       "0                          1.0                      -1.0   \n",
       "1                          1.0                      -1.0   \n",
       "2                          0.0                      -2.0   \n",
       "3                          1.0                      -1.0   \n",
       "4                          1.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "1700                      -1.0                       0.0   \n",
       "1701                      -1.0                       0.0   \n",
       "1702                      -1.0                       0.0   \n",
       "1703                      -1.0                       0.0   \n",
       "1704                      -1.0                       0.0   \n",
       "\n",
       "      background_mother_hash_2  background_mother_hash_3  \\\n",
       "0                          3.0                       0.0   \n",
       "1                          3.0                       0.0   \n",
       "2                          1.0                       0.0   \n",
       "3                          3.0                       0.0   \n",
       "4                          1.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "1700                       1.0                       0.0   \n",
       "1701                       1.0                       0.0   \n",
       "1702                       1.0                       0.0   \n",
       "1703                       1.0                       0.0   \n",
       "1704                       1.0                       0.0   \n",
       "\n",
       "      background_mother_hash_4  background_mother_hash_5  \\\n",
       "0                          1.0                       0.0   \n",
       "1                          1.0                       0.0   \n",
       "2                          1.0                       0.0   \n",
       "3                          1.0                       0.0   \n",
       "4                          0.0                       0.0   \n",
       "...                        ...                       ...   \n",
       "1700                       1.0                       0.0   \n",
       "1701                       1.0                       0.0   \n",
       "1702                       1.0                       0.0   \n",
       "1703                       1.0                       0.0   \n",
       "1704                       1.0                       0.0   \n",
       "\n",
       "      background_mother_hash_6  background_mother_hash_7  \\\n",
       "0                          0.0                       0.0   \n",
       "1                          0.0                       0.0   \n",
       "2                          0.0                      -1.0   \n",
       "3                          0.0                       0.0   \n",
       "4                          0.0                      -1.0   \n",
       "...                        ...                       ...   \n",
       "1700                       1.0                       0.0   \n",
       "1701                       1.0                       0.0   \n",
       "1702                       1.0                       0.0   \n",
       "1703                       1.0                       0.0   \n",
       "1704                       1.0                       0.0   \n",
       "\n",
       "      background_mother_hash_8  background_mother_hash_9  \n",
       "0                          0.0                       1.0  \n",
       "1                          0.0                       1.0  \n",
       "2                          0.0                       0.0  \n",
       "3                          0.0                       1.0  \n",
       "4                          0.0                       2.0  \n",
       "...                        ...                       ...  \n",
       "1700                      -1.0                       0.0  \n",
       "1701                      -1.0                       0.0  \n",
       "1702                      -1.0                       0.0  \n",
       "1703                      -1.0                       0.0  \n",
       "1704                      -1.0                       0.0  \n",
       "\n",
       "[1705 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "# Read in the data\n",
    "df = pd.read_csv('../Data/hashed_combined.csv')\n",
    "df.drop(['fitspatrick','region_hash_0','region_hash_1','region_hash_2','region_hash_3','region_hash_4','region_hash_5','region_hash_6','region_hash_7','region_hash_8','region_hash_9','changed','bleed','elevation','biopsed','diameter_2','diameter_1','itch','grew','hurt'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1705 entries, 0 to 1704\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   smoke                     1705 non-null   bool   \n",
      " 1   drink                     1705 non-null   bool   \n",
      " 2   age                       1705 non-null   int64  \n",
      " 3   pesticide                 1705 non-null   bool   \n",
      " 4   gender                    1705 non-null   int64  \n",
      " 5   skin_cancer_history       1705 non-null   bool   \n",
      " 6   cancer_history            1705 non-null   bool   \n",
      " 7   has_piped_water           1705 non-null   bool   \n",
      " 8   has_sewage_system         1705 non-null   bool   \n",
      " 9   diagnostic                1705 non-null   int64  \n",
      " 10  background_father_hash_0  1705 non-null   float64\n",
      " 11  background_father_hash_1  1705 non-null   float64\n",
      " 12  background_father_hash_2  1705 non-null   float64\n",
      " 13  background_father_hash_3  1705 non-null   float64\n",
      " 14  background_father_hash_4  1705 non-null   float64\n",
      " 15  background_father_hash_5  1705 non-null   float64\n",
      " 16  background_father_hash_6  1705 non-null   float64\n",
      " 17  background_father_hash_7  1705 non-null   float64\n",
      " 18  background_father_hash_8  1705 non-null   float64\n",
      " 19  background_father_hash_9  1705 non-null   float64\n",
      " 20  background_mother_hash_0  1705 non-null   float64\n",
      " 21  background_mother_hash_1  1705 non-null   float64\n",
      " 22  background_mother_hash_2  1705 non-null   float64\n",
      " 23  background_mother_hash_3  1705 non-null   float64\n",
      " 24  background_mother_hash_4  1705 non-null   float64\n",
      " 25  background_mother_hash_5  1705 non-null   float64\n",
      " 26  background_mother_hash_6  1705 non-null   float64\n",
      " 27  background_mother_hash_7  1705 non-null   float64\n",
      " 28  background_mother_hash_8  1705 non-null   float64\n",
      " 29  background_mother_hash_9  1705 non-null   float64\n",
      "dtypes: bool(7), float64(20), int64(3)\n",
      "memory usage: 318.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def splitting_data(df, sampling):\n",
    "    X = df.drop(['diagnostic'], axis=1)\n",
    "    y = df['diagnostic']\n",
    "\n",
    "    if sampling == 'none':\n",
    "        return X, y\n",
    "    elif sampling == 'SMOTEENN':\n",
    "        sampler = SMOTEENN(random_state=random_state)\n",
    "    elif sampling == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    elif sampling == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    elif sampling == 'over':\n",
    "        sampler = RandomOverSampler(random_state=random_state)\n",
    "    elif sampling == 'cluster_centroids':\n",
    "        sampler = ClusterCentroids(random_state=random_state)\n",
    "    elif sampling == 'tomek_links':\n",
    "        sampler = TomekLinks()\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train):\n",
    "    # Create a KNN classifier with 5 neighbors\n",
    "    DT = DecisionTreeClassifier(random_state=random_state)\n",
    "    # Fit the classifier to the data\n",
    "    DT.fit(X_train, y_train)\n",
    "    return DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(modelName, accuracy, precision, recall, f1):\n",
    "    best_model[modelName] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(modleName, DT, X_test ,y_test):\n",
    "    # Predict the labels for the training data X\n",
    "    y_pred = DT.predict(X_test)\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # cr=classification_report(y_test, y_pred, output_dict=True)\n",
    "    # precision = cr['weighted avg']['precision']\n",
    "    # recall = cr['weighted avg']['recall']\n",
    "    # f1 = cr['weighted avg']['f1-score']\n",
    "    # best_model(modleName,accuracy,precision,recall,f1)\n",
    "    cr=classification_report(y_test, y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def optimize_with_grid(X_train, y_train):\n",
    "    # Define a pipeline that first scales the data and then applies the classifier\n",
    "    pipe = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('dt', DecisionTreeClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'dt__min_samples_split': [2, 5, 10],\n",
    "        'dt__min_samples_leaf': [1, 2, 4],\n",
    "        'dt__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    DT_cv = GridSearchCV(pipe,param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Perform the grid search on the provided data\n",
    "    DT_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    best_params = DT_cv.best_params_\n",
    "    best_score = DT_cv.best_score_\n",
    "    best_estimator = DT_cv.best_estimator_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "\n",
    "    return best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on original data with optimization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function with no sampling \n",
    "X, y= splitting_data(df, 'none')\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1494\n",
      "0     211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        37\n",
      "           1       1.00      1.00      1.00       304\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      0.99      0.99       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT1 =training(X_train, y_train)\n",
    "y_pred = predict('original',DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 4, 'dt__min_samples_split': 2}\n",
      "0.9978021978021978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        37\n",
      "           1       1.00      1.00      1.00       304\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      0.99      0.99       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT1 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('original_grid',best_DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTE sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTE')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1494\n",
      "0    1494\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       284\n",
      "           1       1.00      0.99      1.00       314\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT2 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTE',DT2, X_test, y_test)\n",
    "\n",
    "# # Assume 'model' is your trained model\n",
    "# dump(DT2, '../Models/DT_SMOTE.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 2, 'dt__min_samples_split': 2}\n",
      "0.999163179916318\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       284\n",
      "           1       1.00      0.99      1.00       314\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT2 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTE_grid',best_DT2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTEENN sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTEENN')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    1493\n",
      "1    1481\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       304\n",
      "           1       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00       595\n",
      "   macro avg       1.00      1.00      1.00       595\n",
      "weighted avg       1.00      1.00      1.00       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT3 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTEENN',DT3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.9991596638655462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       304\n",
      "           1       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00       595\n",
      "   macro avg       1.00      1.00      1.00       595\n",
      "weighted avg       1.00      1.00      1.00       595\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT3 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTEENN_grid',best_DT3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Random undersampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'under')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    211\n",
      "1    211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99        85\n",
      "   macro avg       0.99      0.99      0.99        85\n",
      "weighted avg       0.99      0.99      0.99        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT4 =training(X_train, y_train)\n",
    "y_pred = predict('undersampling',DT4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.9940298507462686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99        85\n",
      "   macro avg       0.99      0.99      0.99        85\n",
      "weighted avg       0.99      0.99      0.99        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT4 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('undersampling_grid',best_DT4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Random Oversampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df,'over')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    1494\n",
      "0    1494\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       292\n",
      "           1       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT5 =training(X_train, y_train)\n",
    "y_pred = predict('oversampling',DT5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.999581589958159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       292\n",
      "           1       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT5 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('oversampling_grid',best_DT5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Cluster Centroids </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'cluster_centroids')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    211\n",
      "1    211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.94      0.97        50\n",
      "\n",
      "    accuracy                           0.96        85\n",
      "   macro avg       0.96      0.97      0.96        85\n",
      "weighted avg       0.97      0.96      0.96        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT6 = training(X_train, y_train)\n",
    "y_pred = predict('cluster_centroids',DT6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 10}\n",
      "0.9940298507462686\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT6 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('cluster_centroids_grid',best_DT6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Tomek Links </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'tomek_links')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    1493\n",
      "0     211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       1.00      1.00      1.00       298\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      0.99      0.99       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT7 =training(X_train, y_train)\n",
    "y_pred = predict('tomek_links',DT7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.9985321051497522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       1.00      1.00      1.00       298\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      0.99      0.99       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT7 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('tomek_links_grid',best_DT7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.best_model(modelName, accuracy, precision, recall, f1)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m best_model_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m best_model_df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:1664\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1662\u001b[0m orient \u001b[38;5;241m=\u001b[39m orient\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1665\u001b[0m         \u001b[38;5;66;03m# TODO speed up Series case\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m], (Series, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m   1667\u001b[0m             data \u001b[38;5;241m=\u001b[39m _from_nested_dict(data)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "best_model_df = pd.DataFrame.from_dict(best_model, orient='index')\n",
    "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
