{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state=42\n",
    "best_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smoke</th>\n",
       "      <th>drink</th>\n",
       "      <th>age</th>\n",
       "      <th>pesticide</th>\n",
       "      <th>gender</th>\n",
       "      <th>skin_cancer_history</th>\n",
       "      <th>cancer_history</th>\n",
       "      <th>has_piped_water</th>\n",
       "      <th>has_sewage_system</th>\n",
       "      <th>fitspatrick</th>\n",
       "      <th>...</th>\n",
       "      <th>diameter_1</th>\n",
       "      <th>diameter_2</th>\n",
       "      <th>diagnostic</th>\n",
       "      <th>itch</th>\n",
       "      <th>grew</th>\n",
       "      <th>hurt</th>\n",
       "      <th>changed</th>\n",
       "      <th>bleed</th>\n",
       "      <th>elevation</th>\n",
       "      <th>biopsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>74</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>58</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1705 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      smoke  drink  age  pesticide  gender  skin_cancer_history  \\\n",
       "0     False  False   55      False       0                 True   \n",
       "1     False   True   79      False       1                 True   \n",
       "2     False   True   52      False       0                False   \n",
       "3     False  False   74       True       0                False   \n",
       "4     False   True   58       True       0                 True   \n",
       "...     ...    ...  ...        ...     ...                  ...   \n",
       "1700  False  False   23       True       0                False   \n",
       "1701  False  False   27      False       0                False   \n",
       "1702   True   True   23      False       1                False   \n",
       "1703  False  False   23       True       0                False   \n",
       "1704  False  False   21      False       0                False   \n",
       "\n",
       "      cancer_history  has_piped_water  has_sewage_system  fitspatrick  ...  \\\n",
       "0               True             True               True          3.0  ...   \n",
       "1              False            False              False          1.0  ...   \n",
       "2               True             True               True          3.0  ...   \n",
       "3              False            False              False          1.0  ...   \n",
       "4               True             True               True          1.0  ...   \n",
       "...              ...              ...                ...          ...  ...   \n",
       "1700            True             True               True          0.0  ...   \n",
       "1701           False             True               True          0.0  ...   \n",
       "1702           False             True               True          0.0  ...   \n",
       "1703           False             True              False          0.0  ...   \n",
       "1704           False             True               True          0.0  ...   \n",
       "\n",
       "      diameter_1  diameter_2  diagnostic   itch   grew   hurt  changed  bleed  \\\n",
       "0            6.0         5.0           1   True   True  False     True   True   \n",
       "1            5.0         5.0           1   True   True  False    False   True   \n",
       "2           15.0        10.0           1  False   True  False     True   True   \n",
       "3           15.0        10.0           1   True   True   True    False   True   \n",
       "4            9.0         7.0           1  False   True  False    False  False   \n",
       "...          ...         ...         ...    ...    ...    ...      ...    ...   \n",
       "1700         0.0         0.0           0  False  False  False    False  False   \n",
       "1701         0.0         0.0           0  False  False  False    False  False   \n",
       "1702         0.0         0.0           0  False  False  False    False  False   \n",
       "1703         0.0         0.0           0  False  False  False    False  False   \n",
       "1704         0.0         0.0           0  False  False  False    False  False   \n",
       "\n",
       "      elevation  biopsed  \n",
       "0          True     True  \n",
       "1          True     True  \n",
       "2          True     True  \n",
       "3          True     True  \n",
       "4         False    False  \n",
       "...         ...      ...  \n",
       "1700      False    False  \n",
       "1701      False    False  \n",
       "1702      False    False  \n",
       "1703      False    False  \n",
       "1704      False    False  \n",
       "\n",
       "[1705 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "df = pd.read_csv('../Data/FS_combined_skin_cancer.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1705 entries, 0 to 1704\n",
      "Data columns (total 21 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   smoke                1705 non-null   bool   \n",
      " 1   drink                1705 non-null   bool   \n",
      " 2   age                  1705 non-null   int64  \n",
      " 3   pesticide            1705 non-null   bool   \n",
      " 4   gender               1705 non-null   int64  \n",
      " 5   skin_cancer_history  1705 non-null   bool   \n",
      " 6   cancer_history       1705 non-null   bool   \n",
      " 7   has_piped_water      1705 non-null   bool   \n",
      " 8   has_sewage_system    1705 non-null   bool   \n",
      " 9   fitspatrick          1705 non-null   float64\n",
      " 10  region               1705 non-null   int64  \n",
      " 11  diameter_1           1705 non-null   float64\n",
      " 12  diameter_2           1705 non-null   float64\n",
      " 13  diagnostic           1705 non-null   int64  \n",
      " 14  itch                 1705 non-null   bool   \n",
      " 15  grew                 1705 non-null   bool   \n",
      " 16  hurt                 1705 non-null   bool   \n",
      " 17  changed              1705 non-null   bool   \n",
      " 18  bleed                1705 non-null   bool   \n",
      " 19  elevation            1705 non-null   bool   \n",
      " 20  biopsed              1705 non-null   bool   \n",
      "dtypes: bool(14), float64(3), int64(4)\n",
      "memory usage: 116.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "def splitting_data(df, sampling):\n",
    "    X = df.drop(['diagnostic'], axis=1)\n",
    "    y = df['diagnostic']\n",
    "\n",
    "    if sampling == 'none':\n",
    "        return X, y\n",
    "    elif sampling == 'SMOTEENN':\n",
    "        sampler = SMOTEENN(random_state=random_state)\n",
    "    elif sampling == 'SMOTE':\n",
    "        sampler = SMOTE(random_state=random_state)\n",
    "    elif sampling == 'under':\n",
    "        sampler = RandomUnderSampler(random_state=random_state)\n",
    "    elif sampling == 'over':\n",
    "        sampler = RandomOverSampler(random_state=random_state)\n",
    "    elif sampling == 'cluster_centroids':\n",
    "        sampler = ClusterCentroids(random_state=random_state)\n",
    "    elif sampling == 'tomek_links':\n",
    "        sampler = TomekLinks()\n",
    "\n",
    "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(X_train, y_train):\n",
    "    # Create a KNN classifier with 5 neighbors\n",
    "    DT = DecisionTreeClassifier(random_state=random_state)\n",
    "    # Fit the classifier to the data\n",
    "    DT.fit(X_train, y_train)\n",
    "    return DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(modelName, accuracy, precision, recall, f1):\n",
    "    best_model[modelName] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(modleName, DT, X_test ,y_test):\n",
    "    # Predict the labels for the training data X\n",
    "    y_pred = DT.predict(X_test)\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # cr=classification_report(y_test, y_pred, output_dict=True)\n",
    "    # precision = cr['weighted avg']['precision']\n",
    "    # recall = cr['weighted avg']['recall']\n",
    "    # f1 = cr['weighted avg']['f1-score']\n",
    "    # best_model(modleName,accuracy,precision,recall,f1)\n",
    "    cr=classification_report(y_test, y_pred)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def optimize_with_grid(X_train, y_train):\n",
    "    # Define a pipeline that first scales the data and then applies the classifier\n",
    "    pipe = Pipeline([\n",
    "        # ('scaler', StandardScaler()),\n",
    "        ('dt', DecisionTreeClassifier(random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    # Define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'dt__max_depth': [None, 10, 20, 30, 40, 50],\n",
    "        'dt__min_samples_split': [2, 5, 10],\n",
    "        'dt__min_samples_leaf': [1, 2, 4],\n",
    "        'dt__criterion': ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    DT_cv = GridSearchCV(pipe,param_grid, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "    # Perform the grid search on the provided data\n",
    "    DT_cv.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and best score\n",
    "    best_params = DT_cv.best_params_\n",
    "    best_score = DT_cv.best_score_\n",
    "    best_estimator = DT_cv.best_estimator_\n",
    "    print(best_params)\n",
    "    print(best_score)\n",
    "\n",
    "    return best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on original data with optimization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using function with no sampling \n",
    "X, y= splitting_data(df, 'none')\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1494\n",
      "0     211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00       304\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT1 =training(X_train, y_train)\n",
    "y_pred = predict('original',DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00       304\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT1 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('original_grid',best_DT1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTE sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTE')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the training set:\n",
      "1    1494\n",
      "0    1494\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check number of observations in each class in the set\n",
    "print(\"Number of observations in each class in the training set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       284\n",
      "           1       1.00      1.00      1.00       314\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT2 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTE',DT2, X_test, y_test)\n",
    "\n",
    "# # Assume 'model' is your trained model\n",
    "# dump(DT2, '../Models/DT_SMOTE.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       284\n",
      "           1       1.00      1.00      1.00       314\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT2 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTE_grid',best_DT2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT using SMOTEENN sampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'SMOTEENN')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    1494\n",
      "1    1494\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       306\n",
      "           1       1.00      1.00      1.00       292\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT3 =training(X_train, y_train)\n",
    "y_pred = predict('SMOTEENN',DT3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       306\n",
      "           1       1.00      1.00      1.00       292\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT3 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('SMOTEENN_grid',best_DT3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Random undersampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'under')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    211\n",
      "1    211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT4 =training(X_train, y_train)\n",
    "y_pred = predict('undersampling',DT4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "0.9970588235294118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00        50\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT4 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('undersampling_grid',best_DT4, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Random Oversampling </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df,'over')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    1494\n",
      "0    1494\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       292\n",
      "           1       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT5 =training(X_train, y_train)\n",
    "y_pred = predict('oversampling',DT5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       292\n",
      "           1       1.00      1.00      1.00       306\n",
      "\n",
      "    accuracy                           1.00       598\n",
      "   macro avg       1.00      1.00      1.00       598\n",
      "weighted avg       1.00      1.00      1.00       598\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT5 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('oversampling_grid',best_DT5, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Cluster Centroids </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maryam/opt/anaconda3/lib/python3.9/site-packages/imblearn/under_sampling/_prototype_generation/_cluster_centroids.py:178: ConvergenceWarning: Number of distinct clusters (199) found smaller than n_clusters (211). Possibly due to duplicate points in X.\n",
      "  self.estimator_.fit(_safe_indexing(X, target_class_indices))\n"
     ]
    }
   ],
   "source": [
    "X,y = splitting_data(df, 'cluster_centroids')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "0    211\n",
      "1    211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99        85\n",
      "   macro avg       0.99      0.99      0.99        85\n",
      "weighted avg       0.99      0.99      0.99        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT6 = training(X_train, y_train)\n",
    "y_pred = predict('cluster_centroids',DT6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        35\n",
      "           1       1.00      0.98      0.99        50\n",
      "\n",
      "    accuracy                           0.99        85\n",
      "   macro avg       0.99      0.99      0.99        85\n",
      "weighted avg       0.99      0.99      0.99        85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT6 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('cluster_centroids_grid',best_DT6, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DT on Tomek Links </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = splitting_data(df, 'tomek_links')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in each class in the set:\n",
      "1    1494\n",
      "0     211\n",
      "Name: diagnostic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of observations in each class in the set:\")\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00       302\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "DT7 =training(X_train, y_train)\n",
    "y_pred = predict('tomek_links',DT7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "{'dt__criterion': 'gini', 'dt__max_depth': None, 'dt__min_samples_leaf': 1, 'dt__min_samples_split': 2}\n",
      "1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00       302\n",
      "\n",
      "    accuracy                           1.00       341\n",
      "   macro avg       1.00      1.00      1.00       341\n",
      "weighted avg       1.00      1.00      1.00       341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_DT7 = optimize_with_grid(X_train, y_train)\n",
    "prediction = predict('tomek_links_grid',best_DT7, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.best_model(modelName, accuracy, precision, recall, f1)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'function' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m best_model_df\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m best_model_df\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:1664\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1662\u001b[0m orient \u001b[38;5;241m=\u001b[39m orient\u001b[38;5;241m.\u001b[39mlower()\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1664\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1665\u001b[0m         \u001b[38;5;66;03m# TODO speed up Series case\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mlist\u001b[39m(data\u001b[38;5;241m.\u001b[39mvalues())[\u001b[38;5;241m0\u001b[39m], (Series, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[1;32m   1667\u001b[0m             data \u001b[38;5;241m=\u001b[39m _from_nested_dict(data)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'function' has no len()"
     ]
    }
   ],
   "source": [
    "best_model_df = pd.DataFrame.from_dict(best_model, orient='index')\n",
    "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
    "best_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
