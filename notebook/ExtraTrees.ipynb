{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNdDQEobqKII",
        "outputId": "aa32d5c3-de41-4bd4-e7e1-0b034129acc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lightgbm in /Users/maryam/opt/anaconda3/lib/python3.9/site-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /Users/maryam/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.24.3)\n",
            "Requirement already satisfied: scipy in /Users/maryam/opt/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.9.1)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.discriminant_analysis import StandardScaler\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%pip install lightgbm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "88NenbxiqKIJ"
      },
      "outputs": [],
      "source": [
        "random_state=42\n",
        "best_models = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "VY2BqdWOqKIJ",
        "outputId": "aedf2944-28cb-4d62-de33-8c0e671e78df"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>smoke</th>\n",
              "      <th>drink</th>\n",
              "      <th>age</th>\n",
              "      <th>pesticide</th>\n",
              "      <th>gender</th>\n",
              "      <th>skin_cancer_history</th>\n",
              "      <th>cancer_history</th>\n",
              "      <th>has_piped_water</th>\n",
              "      <th>has_sewage_system</th>\n",
              "      <th>diagnostic</th>\n",
              "      <th>...</th>\n",
              "      <th>background_mother_hash_0</th>\n",
              "      <th>background_mother_hash_1</th>\n",
              "      <th>background_mother_hash_2</th>\n",
              "      <th>background_mother_hash_3</th>\n",
              "      <th>background_mother_hash_4</th>\n",
              "      <th>background_mother_hash_5</th>\n",
              "      <th>background_mother_hash_6</th>\n",
              "      <th>background_mother_hash_7</th>\n",
              "      <th>background_mother_hash_8</th>\n",
              "      <th>background_mother_hash_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>55</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>79</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>52</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>74</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>58</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1700</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>27</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1702</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "      <td>False</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1703</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>23</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1704</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>21</td>\n",
              "      <td>False</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1705 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      smoke  drink  age  pesticide  gender  skin_cancer_history  \\\n",
              "0     False  False   55      False       0                 True   \n",
              "1     False   True   79      False       1                 True   \n",
              "2     False   True   52      False       0                False   \n",
              "3     False  False   74       True       0                False   \n",
              "4     False   True   58       True       0                 True   \n",
              "...     ...    ...  ...        ...     ...                  ...   \n",
              "1700  False  False   23       True       0                False   \n",
              "1701  False  False   27      False       0                False   \n",
              "1702   True   True   23      False       1                False   \n",
              "1703  False  False   23       True       0                False   \n",
              "1704  False  False   21      False       0                False   \n",
              "\n",
              "      cancer_history  has_piped_water  has_sewage_system  diagnostic  ...  \\\n",
              "0               True             True               True           1  ...   \n",
              "1              False            False              False           1  ...   \n",
              "2               True             True               True           1  ...   \n",
              "3              False            False              False           1  ...   \n",
              "4               True             True               True           1  ...   \n",
              "...              ...              ...                ...         ...  ...   \n",
              "1700            True             True               True           0  ...   \n",
              "1701           False             True               True           0  ...   \n",
              "1702           False             True               True           0  ...   \n",
              "1703           False             True              False           0  ...   \n",
              "1704           False             True               True           0  ...   \n",
              "\n",
              "      background_mother_hash_0  background_mother_hash_1  \\\n",
              "0                          1.0                      -1.0   \n",
              "1                          1.0                      -1.0   \n",
              "2                          0.0                      -2.0   \n",
              "3                          1.0                      -1.0   \n",
              "4                          1.0                       0.0   \n",
              "...                        ...                       ...   \n",
              "1700                      -1.0                       0.0   \n",
              "1701                      -1.0                       0.0   \n",
              "1702                      -1.0                       0.0   \n",
              "1703                      -1.0                       0.0   \n",
              "1704                      -1.0                       0.0   \n",
              "\n",
              "      background_mother_hash_2  background_mother_hash_3  \\\n",
              "0                          3.0                       0.0   \n",
              "1                          3.0                       0.0   \n",
              "2                          1.0                       0.0   \n",
              "3                          3.0                       0.0   \n",
              "4                          1.0                       0.0   \n",
              "...                        ...                       ...   \n",
              "1700                       1.0                       0.0   \n",
              "1701                       1.0                       0.0   \n",
              "1702                       1.0                       0.0   \n",
              "1703                       1.0                       0.0   \n",
              "1704                       1.0                       0.0   \n",
              "\n",
              "      background_mother_hash_4  background_mother_hash_5  \\\n",
              "0                          1.0                       0.0   \n",
              "1                          1.0                       0.0   \n",
              "2                          1.0                       0.0   \n",
              "3                          1.0                       0.0   \n",
              "4                          0.0                       0.0   \n",
              "...                        ...                       ...   \n",
              "1700                       1.0                       0.0   \n",
              "1701                       1.0                       0.0   \n",
              "1702                       1.0                       0.0   \n",
              "1703                       1.0                       0.0   \n",
              "1704                       1.0                       0.0   \n",
              "\n",
              "      background_mother_hash_6  background_mother_hash_7  \\\n",
              "0                          0.0                       0.0   \n",
              "1                          0.0                       0.0   \n",
              "2                          0.0                      -1.0   \n",
              "3                          0.0                       0.0   \n",
              "4                          0.0                      -1.0   \n",
              "...                        ...                       ...   \n",
              "1700                       1.0                       0.0   \n",
              "1701                       1.0                       0.0   \n",
              "1702                       1.0                       0.0   \n",
              "1703                       1.0                       0.0   \n",
              "1704                       1.0                       0.0   \n",
              "\n",
              "      background_mother_hash_8  background_mother_hash_9  \n",
              "0                          0.0                       1.0  \n",
              "1                          0.0                       1.0  \n",
              "2                          0.0                       0.0  \n",
              "3                          0.0                       1.0  \n",
              "4                          0.0                       2.0  \n",
              "...                        ...                       ...  \n",
              "1700                      -1.0                       0.0  \n",
              "1701                      -1.0                       0.0  \n",
              "1702                      -1.0                       0.0  \n",
              "1703                      -1.0                       0.0  \n",
              "1704                      -1.0                       0.0  \n",
              "\n",
              "[1705 rows x 30 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read in the data\n",
        "df = pd.read_csv('../Data/hashed_combined.csv')\n",
        "df.drop(['fitspatrick','region_hash_0','region_hash_1','region_hash_2','region_hash_3','region_hash_4','region_hash_5','region_hash_6','region_hash_7','region_hash_8','region_hash_9','changed','bleed','elevation','biopsed','diameter_2','diameter_1','itch','grew','hurt'], axis=1, inplace=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQX8dggmPB8c"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uNLe-VlTqKIK"
      },
      "outputs": [],
      "source": [
        "from imblearn.under_sampling import ClusterCentroids, TomekLinks\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "def splitting_data(df, sampling):\n",
        "    X = df.drop(['diagnostic'], axis=1)\n",
        "    y = df['diagnostic']\n",
        "\n",
        "    if sampling == 'none':\n",
        "        return X, y\n",
        "    elif sampling == 'SMOTEENN':\n",
        "        sampler = SMOTEENN(random_state=random_state)\n",
        "    elif sampling == 'SMOTE':\n",
        "        sampler = SMOTE(random_state=random_state)\n",
        "    elif sampling == 'under':\n",
        "        sampler = RandomUnderSampler(random_state=random_state)\n",
        "    elif sampling == 'over':\n",
        "        sampler = RandomOverSampler(random_state=random_state)\n",
        "    elif sampling == 'cluster_centroids':\n",
        "        sampler = ClusterCentroids(random_state=random_state)\n",
        "    elif sampling == 'tomek_links':\n",
        "        sampler = TomekLinks()\n",
        "\n",
        "    X_resampled, y_resampled = sampler.fit_resample(X, y)\n",
        "    return X_resampled, y_resampled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lVVxj7KAqKIK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def training(X_train, y_train):\n",
        "    # Create a KNN classifier with 5 neighbors\n",
        "    LGBM = ExtraTreesClassifier()\n",
        "    # Fit the classifier to the data\n",
        "    LGBM.fit(X_train, y_train)\n",
        "    return LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3Zc5GvysOfGU"
      },
      "outputs": [],
      "source": [
        "def best_model(modelName, accuracy, precision, recall, f1):\n",
        "    best_models[modelName] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Qx40EAZCqKIK"
      },
      "outputs": [],
      "source": [
        "def predict(modleName,LGBM, X_test ,y_test):\n",
        "    # Predict the labels for the training data X\n",
        "    y_pred = LGBM.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    cr=classification_report(y_test, y_pred, output_dict=True)\n",
        "    precision = cr['weighted avg']['precision']\n",
        "    recall = cr['weighted avg']['recall']\n",
        "    f1 = cr['weighted avg']['f1-score']\n",
        "    best_model(modleName,accuracy,precision,recall,f1)\n",
        "    cr=classification_report(y_test, y_pred)\n",
        "    print(cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwAOn-8uqKIK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RaCvmccpqKIK"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "def optimize_with_grid(X_train, y_train):\n",
        "    # Define a pipeline\n",
        "    # Note: Scaling might not be necessary for tree-based models, but included for consistency\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Optional for ExtraTrees\n",
        "        ('extra_trees', ExtraTreesClassifier(random_state=random_state))\n",
        "    ])\n",
        "\n",
        "    # Define the parameter grid to search\n",
        "    param_grid = {\n",
        "        'extra_trees__n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
        "        'extra_trees__max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
        "        'extra_trees__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
        "        'extra_trees__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
        "        'extra_trees__max_features': ['auto', 'sqrt', 'log2']  # Number of features to consider when looking for the best split\n",
        "    }\n",
        "\n",
        "    # Create the GridSearchCV object\n",
        "    extra_trees_cv = GridSearchCV(pipe, param_grid, cv=5, verbose=1, n_jobs=-1)\n",
        "\n",
        "    # Perform the grid search on the provided data\n",
        "    extra_trees_cv.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters and best score\n",
        "    best_params = extra_trees_cv.best_params_\n",
        "    best_score = extra_trees_cv.best_score_\n",
        "    best_estimator = extra_trees_cv.best_estimator_\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Score:\", best_score)\n",
        "\n",
        "    return best_estimator\n",
        "\n",
        "# Example usage\n",
        "# Ensure you have defined X_train, y_train, and optionally random_state before calling this function\n",
        "# best_extra_trees_model = optimize_with_grid_extra_trees(X_train, y_train, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymbIYYOgqKIK"
      },
      "source": [
        "<h1> LGBM on original data with optimization </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jNHPeleDqKIL"
      },
      "outputs": [],
      "source": [
        "# using function with no sampling\n",
        "X, y= splitting_data(df, 'none')\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9HGLHNvqKIL",
        "outputId": "c660b805-d8f7-48c0-fa12-e342f729c21a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "1    1494\n",
            "0     211\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mo1V3LfNqKIL",
        "outputId": "c81988db-7320-4803-9ca0-12ca8e6c7bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        37\n",
            "           1       1.00      1.00      1.00       304\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      0.99      0.99       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM1 = training(X_train, y_train)\n",
        "y_pred = predict('original',LGBM1, X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiCcN4wtqKIL",
        "outputId": "4e26eff9-8da4-4ff5-da45-f6ee6add49bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'auto', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 0.9978021978021978\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99        37\n",
            "           1       1.00      1.00      1.00       304\n",
            "\n",
            "    accuracy                           1.00       341\n",
            "   macro avg       1.00      0.99      0.99       341\n",
            "weighted avg       1.00      1.00      1.00       341\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM1 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('original_grid',best_LGBM1, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP50kI6HqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTE sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5QC5Nt4VqKIM"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'SMOTE')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEyeNwUYqKIM",
        "outputId": "94a381cc-d663-43ce-d9cf-da3a66c45504"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the training set:\n",
            "1    1494\n",
            "0    1494\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#check number of observations in each class in the set\n",
        "print(\"Number of observations in each class in the training set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejMPzo7yqKIM",
        "outputId": "1d2f5b71-0bf7-4602-a281-d7746a86a9fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       284\n",
            "           1       1.00      1.00      1.00       314\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM2 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTE',LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA7dtp3BqKIM",
        "outputId": "62195fb4-fddf-44c0-fecc-fbb9be395327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'auto', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 0.999581589958159\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       284\n",
            "           1       1.00      1.00      1.00       314\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM2 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTE_grid',best_LGBM2, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqQKWnBOqKIM"
      },
      "source": [
        "<h1> LGBM using SMOTEENN sampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "i2oPMW0QqKIM"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'SMOTEENN')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSBW__2vqKIM",
        "outputId": "cc80040a-d73b-4335-d3dc-2cc8f82ff736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "0    1493\n",
            "1    1481\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAArrZCsqKIM",
        "outputId": "ceea8710-93d1-4430-d8bc-3be4458ec2d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       304\n",
            "           1       1.00      1.00      1.00       291\n",
            "\n",
            "    accuracy                           1.00       595\n",
            "   macro avg       1.00      1.00      1.00       595\n",
            "weighted avg       1.00      1.00      1.00       595\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM3 =training(X_train, y_train)\n",
        "y_pred = predict('SMOTEENN',LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n30gjeRDUJwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugU45SBeTyNO",
        "outputId": "de07c078-08cd-4073-8547-683066c35f25"
      },
      "outputs": [],
      "source": [
        "# from joblib import dump\n",
        "# dump(LGBM3,'/content/LGBM_SMOTEENN.joblib')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "coDgVriNUIdg"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJO13pfyqKIM",
        "outputId": "fd440418-7f80-42a0-e35c-ddd737434e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'auto', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 0.9991587793011941\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       304\n",
            "           1       1.00      1.00      1.00       291\n",
            "\n",
            "    accuracy                           1.00       595\n",
            "   macro avg       1.00      1.00      1.00       595\n",
            "weighted avg       1.00      1.00      1.00       595\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM3 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('SMOTEENN_grid',best_LGBM3, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PnNxWS7qKIN"
      },
      "source": [
        "<h1> DT on Random undersampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "hyBeGwkxqKIN"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'under')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CngNW2VoqKIN",
        "outputId": "4e5988f1-e887-494e-9094-9f36ec80c007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "0    211\n",
            "1    211\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWfctngdqKIN",
        "outputId": "5f3cc946-e233-4d0d-8dc9-5981be847412"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM4 =training(X_train, y_train)\n",
        "y_pred = predict('undersampling',LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gphc1Qn_qKIN",
        "outputId": "0209143e-94d9-4d5a-83c3-3ae43c82854d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'log2', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 0.9911325724319578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM4 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('undersampling_grid',best_LGBM4, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwX52mz6rJQM"
      },
      "source": [
        "<h1> DT on Random Oversampling </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "vRNY2IctrJQY"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'over')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fQJF0p-rJQY",
        "outputId": "91d1cd54-a355-432b-d511-8707f92a9812"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "1    1494\n",
            "0    1494\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHyDEyJMrJQZ",
        "outputId": "910b50ab-9f84-4f3b-a9b6-67de99d6a906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM5 =training(X_train, y_train)\n",
        "y_pred = predict('oversampling',LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtbUa8ZIrrWY",
        "outputId": "f506ca33-9fd4-46a6-f8ae-21d1e14b7de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'extra_trees__max_depth': None, 'extra_trees__max_features': 'auto', 'extra_trees__min_samples_leaf': 1, 'extra_trees__min_samples_split': 2, 'extra_trees__n_estimators': 100}\n",
            "Best Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       292\n",
            "           1       1.00      1.00      1.00       306\n",
            "\n",
            "    accuracy                           1.00       598\n",
            "   macro avg       1.00      1.00      1.00       598\n",
            "weighted avg       1.00      1.00      1.00       598\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best_LGBM5 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('oversampling_grid',best_LGBM5, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGpTKsmiqKIN"
      },
      "source": [
        "<h1> DT on Cluster Centroids </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkaTFoZVqKIN",
        "outputId": "5dd6d896-8f22-4902-e9ae-fce76914004f"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'cluster_centroids')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS1rSgaxqKIN",
        "outputId": "5962a95b-06f3-41ce-94da-5e35c6e14371"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of observations in each class in the set:\n",
            "0    211\n",
            "1    211\n",
            "Name: diagnostic, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqdTB76UqKIN",
        "outputId": "02ab0f35-37e7-44f2-e8e8-1d1add42d954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        35\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        85\n",
            "   macro avg       1.00      1.00      1.00        85\n",
            "weighted avg       1.00      1.00      1.00        85\n",
            "\n"
          ]
        }
      ],
      "source": [
        "LGBM6 =training(X_train, y_train)\n",
        "y_pred = predict('cluster_centroids',LGBM6, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EeeuE9NqKIN",
        "outputId": "22fe4910-323a-4447-9c15-6f4c480698dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_LGBM6 \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_with_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m predict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcluster_centroids_grid\u001b[39m\u001b[38;5;124m'\u001b[39m,best_LGBM6, X_test, y_test)\n",
            "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36moptimize_with_grid\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     24\u001b[0m extra_trees_cv \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Perform the grid search on the provided data\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mextra_trees_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Best parameters and best score\u001b[39;00m\n\u001b[1;32m     30\u001b[0m best_params \u001b[38;5;241m=\u001b[39m extra_trees_cv\u001b[38;5;241m.\u001b[39mbest_params_\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "best_LGBM6 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('cluster_centroids_grid',best_LGBM6, X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiouy-TeqKIN"
      },
      "source": [
        "<h1> DT on Tomek Links </h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv9E9_GxqKIN"
      },
      "outputs": [],
      "source": [
        "X,y = splitting_data(df, 'tomek_links')\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E5JKBcpqKIO",
        "outputId": "45d71ad9-688e-46e1-a3af-2d41bd99ea52"
      },
      "outputs": [],
      "source": [
        "print(\"Number of observations in each class in the set:\")\n",
        "print(y.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhD1_sXpqKIO",
        "outputId": "72705b23-115d-47fd-ed4f-440fd93a52a2"
      },
      "outputs": [],
      "source": [
        "LGBM7 =training(X_train, y_train)\n",
        "y_pred = predict('tomek_links',LGBM7, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40edJ6c9qKIO",
        "outputId": "83bc31d7-887c-422e-d40a-9f0763642a14"
      },
      "outputs": [],
      "source": [
        "best_LGBM7 = optimize_with_grid(X_train, y_train)\n",
        "prediction = predict('tomek_links_grid',best_LGBM7, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "_KHeS-NAOfGc",
        "outputId": "b266a67b-2bac-4887-cb70-63238ab818dc"
      },
      "outputs": [],
      "source": [
        "best_model_df = pd.DataFrame.from_dict(best_models, orient='index')\n",
        "best_model_df.sort_values(by='accuracy', ascending=False, inplace=True)\n",
        "best_model_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6ECXu3QQryM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
